{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 고객의 id 를 받아 고객 개인정보 테이블에 연결하는 DB\n",
    "# 챗봇 : FAQ, 제품 설명서 등을 RAG 기반으로 검색 및 답변 | 개인 관련 내용은 history로 입력\n",
    "# 배송 API를 어떻게 구성하지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f4d705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 역할 분담\n",
    "\n",
    "# 파일 로드 - 제품설명서 + FAQ 목록 -> vectorDB 에 넣을 거\n",
    "# code/documents.ipynb\n",
    "## 가져와서 metadata 랑 chunking 전처리하고 vectorDB에 넣기까지\n",
    "\n",
    "# RAG 구조 + 모델링 - 메타 데이터 및 쿼리 재생성(HyDE) + vectorDB에서 검색\n",
    "# code/main.ipynb\n",
    "## retriever 생성, 문서 추출 함수 등 \n",
    "## SQL Agent 까지 여기서 구성 \n",
    "\n",
    "# 개인정보용 SQLDataBase 구성 - 고객 정보 테이블, 고객 장바구니?, 고객 주문내역\n",
    "## 해당 정보 관련 query 일 경우 별도의 tool로 개인정보 가져오기\n",
    "\n",
    "# RAG 평가 지표 구성\n",
    "## RAGAS 이용, 지표 골라야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18718132",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_vector_store' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m     retriever = vector_store.as_retriever(search_kwargs={\u001b[33m\"\u001b[39m\u001b[33mk\u001b[39m\u001b[33m\"\u001b[39m:k})\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retriever\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m retriever = \u001b[43mget_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 문서 내용 추출 함수 \u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mformat_docs\u001b[39m(docs:\u001b[38;5;28mlist\u001b[39m[Document]) -> \u001b[38;5;28mstr\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mget_retriever\u001b[39m\u001b[34m(k)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_retriever\u001b[39m(k=\u001b[32m10\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     vector_store = \u001b[43mget_vector_store\u001b[49m()\n\u001b[32m      4\u001b[39m     retriever = vector_store.as_retriever(search_kwargs={\u001b[33m\"\u001b[39m\u001b[33mk\u001b[39m\u001b[33m\"\u001b[39m:k})\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retriever\n",
      "\u001b[31mNameError\u001b[39m: name 'get_vector_store' is not defined"
     ]
    }
   ],
   "source": [
    "# Retriever 생성\n",
    "def get_retriever(k=10):\n",
    "    vector_store = get_vector_store()\n",
    "    retriever = vector_store.as_retriever(search_kwargs={\"k\":k})\n",
    "    return retriever\n",
    "retriever = get_retriever(k=3)\n",
    "\n",
    "# 문서 내용 추출 함수 \n",
    "def format_docs(docs:list[Document]) -> str:\n",
    "    \"\"\"\n",
    "    Retriever가 검색한 문서들에서 page_content(문서 내용) 만 추출해서 반환.\n",
    "    추출된 문서들의 내용을 \"\\n\\n\"로 연결한다.\n",
    "    Args:\n",
    "        docs(list[Document]) - 검색한 문서 리스트\n",
    "    Returns:\n",
    "        str - 문서1내용+\\n\\n문서2내용+\\n\\n .. \n",
    "    \"\"\"\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# HyDE 를 적용해 retriever 호출 함수\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from textwrap import dedent\n",
    "\n",
    "def hyde_retriever(query:str, k=3):\n",
    "    hyde_model = ChatOpenAI(model_name='gpt-4.1')   # 가상답변을 생성하는 모델은 좋은 모델을 사용해야함. 할루시네이션 방지\n",
    "    hyde_prompt_template = PromptTemplate(\n",
    "    template=dedent(\"\"\"# Instruction\n",
    "        다음 질문에 대해서 완전하고 상세한 답변을 실제 사실에 기반해서 작성해 주세요.\n",
    "        질문과 관련된 내용만으로 답변을 작성합니다.\n",
    "        답변과 직접적인 연관성이 없는 내용은 답변에 포함시키지 않습니다.\n",
    "\n",
    "        # 질문 : \n",
    "        {query}\n",
    "        \"\"\")\n",
    "    )\n",
    "    hyde_chain = hyde_prompt_template | hyde_model | StrOutputParser()\n",
    "    retriever = get_retriever(k)\n",
    "    dummy_answer = hyde_chain.invoke({\"query\":query})\n",
    "    return retriever.invoke(dummy_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbe65973",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hyde_retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     39\u001b[39m model = ChatOpenAI(model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4.1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     40\u001b[39m parser = StrOutputParser()\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m chain = ({\u001b[33m\"\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m\"\u001b[39m:RunnableLambda(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m])|\u001b[43mhyde_retriever\u001b[49m|format_docs, \n\u001b[32m     42\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m:RunnablePassthrough()} \n\u001b[32m     43\u001b[39m         | prompt_template\n\u001b[32m     44\u001b[39m         | model\n\u001b[32m     45\u001b[39m         | StrOutputParser()\n\u001b[32m     46\u001b[39m         )\n\u001b[32m     47\u001b[39m chain_with_history = RunnableWithMessageHistory(\n\u001b[32m     48\u001b[39m     runnable=chain,\n\u001b[32m     49\u001b[39m     get_session_history=get_session_history,\n\u001b[32m     50\u001b[39m     input_messages_key=\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     51\u001b[39m     history_messages_key=\u001b[33m\"\u001b[39m\u001b[33mhistory\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     52\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'hyde_retriever' is not defined"
     ]
    }
   ],
   "source": [
    "# 메인 챗봇 모델 구성\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableWithMessageHistory, RunnablePassthrough, RunnableLambda\n",
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# SQL 연결\n",
    "session_id = 'user_1'\n",
    "engine = create_engine(\"mysql+pymysql://jin:1111@localhost:3306/hr\")\n",
    "sql_store = {}\n",
    "def get_session_history(session_id:str)->SQLChatMessageHistory:\n",
    "    if session_id not in sql_store:\n",
    "        sql_store[session_id] = SQLChatMessageHistory(\n",
    "            session_id=session_id,\n",
    "            connection=engine\n",
    "        )\n",
    "    return sql_store[session_id]\n",
    "\n",
    "# 체인 구성\n",
    "system_template = \"\"\"### Instruction:\n",
    "    당신은 AI 전문가입니다.\n",
    "    \n",
    "    ### Context\n",
    "    {context}\n",
    "    \"\"\"\n",
    "    \n",
    "prompt_template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", system_template),\n",
    "        MessagesPlaceholder(variable_name=\"history\", optional=True),\n",
    "        (\"human\", '{query}')\n",
    "    ]\n",
    ")\n",
    "model = ChatOpenAI(model=\"gpt-4.1\")\n",
    "parser = StrOutputParser()\n",
    "chain = ({\"context\":RunnableLambda(lambda x: x[\"query\"])|hyde_retriever|format_docs, \n",
    "        \"query\":RunnablePassthrough()} \n",
    "        | prompt_template\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "        )\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    runnable=chain,\n",
    "    get_session_history=get_session_history,\n",
    "    input_messages_key=\"query\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4422ead",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chain_with_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 실행\u001b[39;00m\n\u001b[32m      2\u001b[39m query = \u001b[38;5;28minput\u001b[39m()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m response = \u001b[43mchain_with_history\u001b[49m.invoke(\n\u001b[32m      4\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m:query}, \n\u001b[32m      5\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m:{\u001b[33m\"\u001b[39m\u001b[33msession_id\u001b[39m\u001b[33m\"\u001b[39m:session_id}})\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mquery : \u001b[39m\u001b[33m\"\u001b[39m, query)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mresponse : \u001b[39m\u001b[33m\"\u001b[39m, response)\n",
      "\u001b[31mNameError\u001b[39m: name 'chain_with_history' is not defined"
     ]
    }
   ],
   "source": [
    "# 실행\n",
    "query = input()\n",
    "response = chain_with_history.invoke(\n",
    "    {\"query\":query}, \n",
    "    {\"configurable\":{\"session_id\":session_id}})\n",
    "print(\"query : \", query)\n",
    "print(\"response : \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826f3373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9146c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
