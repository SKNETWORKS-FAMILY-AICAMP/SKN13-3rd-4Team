"""
RAG (Retrieval-Augmented Generation) í”„ë¡œì„¸ì„œ
ë²¡í„° DBë¥¼ ì‚¬ìš©í•œ ë¬¸ì„œ ê²€ìƒ‰ ë° ì‘ë‹µ ìƒì„±
"""
import json
import time
from pathlib import Path
from typing import Dict, Any, List, Optional

from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv

load_dotenv()


class RAGProcessor:
    """RAG ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ ë° ì‘ë‹µ ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self, model_name: str = "gpt-4o-mini"):
        self.model_name = model_name
        self.llm = ChatOpenAI(model=model_name, temperature=0.1)
        self.embeddings = OpenAIEmbeddings()
        self.vectorstore = None
        
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
        self.project_root = Path(__file__).parent.parent
        self.vector_db_path = self.project_root / "data" / "vectordb_chroma"
        self.raw_docs_path = self.project_root / "data" / "raw_docs"
    
    def initialize_vector_store(self):
        """ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”"""
        try:
            if self.vector_db_path.exists():
                # ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ
                self.vectorstore = Chroma(
                    persist_directory=str(self.vector_db_path),
                    embedding_function=self.embeddings
                )
                print(f"âœ… ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ: {self.vector_db_path}")
            else:
                # ìƒˆë¡œìš´ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
                print("âš ï¸ ë²¡í„° ìŠ¤í† ì–´ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...")
                self._create_vector_store()
        except Exception as e:
            print(f"âŒ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def _create_vector_store(self):
        """ë²¡í„° ìŠ¤í† ì–´ ìƒì„±"""
        documents = self._load_documents()
        
        if not documents:
            raise ValueError("ë¡œë“œí•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
        self.vector_db_path.mkdir(parents=True, exist_ok=True)
        self.vectorstore = Chroma.from_documents(
            documents=documents,
            embedding=self.embeddings,
            persist_directory=str(self.vector_db_path)
        )
        
        # ì €ì¥
        self.vectorstore.persist()
        print(f"âœ… ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ: {self.vector_db_path}")
    
    def _load_documents(self) -> List[Document]:
        """ë¬¸ì„œ ë¡œë“œ ë° Document ê°ì²´ ë³€í™˜"""
        documents = []
        
        # FAQ ë¬¸ì„œ ì²˜ë¦¬
        faq_documents = self._process_faq_documents()
        documents.extend(faq_documents)
        
        # ì œí’ˆ ì •ë³´ ë¬¸ì„œ ì²˜ë¦¬
        product_documents = self._process_product_documents()
        documents.extend(product_documents)
        
        return documents
    
    def _process_faq_documents(self) -> List[Document]:
        """FAQ ë¬¸ì„œ ì²˜ë¦¬"""
        documents = []
        faq_file = self.raw_docs_path / "faq_data.json"
        
        if not faq_file.exists():
            print(f"âš ï¸ FAQ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {faq_file}")
            return documents
        
        try:
            with open(faq_file, 'r', encoding='utf-8') as f:
                faq_data = json.load(f)
            
            for faq in faq_data:
                content = f"ì§ˆë¬¸: {faq['question']}\në‹µë³€: {faq['answer']}"
                doc = Document(
                    page_content=content,
                    metadata={
                        "source": "faq",
                        "category": faq.get('category', 'general'),
                        "faq_id": faq.get('id', ''),
                        "keywords": faq.get('keywords', [])
                    }
                )
                documents.append(doc)
            
            print(f"âœ… FAQ ë¬¸ì„œ {len(documents)}ê°œ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ FAQ ë¬¸ì„œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return documents
    
    def _process_product_documents(self) -> List[Document]:
        """ì œí’ˆ ì •ë³´ ë¬¸ì„œ ì²˜ë¦¬"""
        documents = []
        product_file = self.raw_docs_path / "product_info.json"
        
        if not product_file.exists():
            print(f"âš ï¸ ì œí’ˆ ì •ë³´ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {product_file}")
            return documents
        
        try:
            with open(product_file, 'r', encoding='utf-8') as f:
                product_data = json.load(f)
            
            for product in product_data:
                # ì œí’ˆ ì •ë³´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                content_parts = [
                    f"ì œí’ˆëª…: {product['name']}",
                    f"ê°€ê²©: {product['price']:,}ì›",
                    f"ì„¤ëª…: {product['description']}"
                ]
                
                if 'specifications' in product:
                    specs = product['specifications']
                    content_parts.append("ì‚¬ì–‘:")
                    for key, value in specs.items():
                        content_parts.append(f"- {key}: {value}")
                
                content = "\n".join(content_parts)
                
                doc = Document(
                    page_content=content,
                    metadata={
                        "source": "product",
                        "product_id": product.get('id', ''),
                        "category": product.get('category', ''),
                        "price": product.get('price', 0),
                        "name": product.get('name', '')
                    }
                )
                documents.append(doc)
            
            print(f"âœ… ì œí’ˆ ì •ë³´ ë¬¸ì„œ {len(documents)}ê°œ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ì œí’ˆ ì •ë³´ ë¬¸ì„œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return documents
    
    def process_query(self, query: str, k: int = 3) -> Dict[str, Any]:
        """
        ì¿¼ë¦¬ ì²˜ë¦¬ ë° ì‘ë‹µ ìƒì„±
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            k: ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜
            
        Returns:
            ì‘ë‹µ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        start_time = time.time()
        
        if not self.vectorstore:
            return {
                "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ê²€ìƒ‰ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "confidence": 0.0,
                "sources": [],
                "response_time": time.time() - start_time
            }
        
        try:
            # ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰
            search_results = self.vectorstore.similarity_search(query, k=k)
            
            if not search_results:
                return {
                    "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "confidence": 0.0,
                    "sources": [],
                    "response_time": time.time() - start_time
                }
            
            # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            context = self._format_search_results(search_results)
            
            # LLMì„ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„±
            response = self._generate_response(query, context)
            
            # ì†ŒìŠ¤ ì •ë³´ ì¶”ì¶œ
            sources = self._extract_source_info(search_results)
            
            # ì‹ ë¢°ë„ ê³„ì‚° (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
            confidence = self._calculate_confidence(search_results, query)
            
            return {
                "response": response,
                "confidence": confidence,
                "sources": sources,
                "response_time": time.time() - start_time
            }
            
        except Exception as e:
            return {
                "response": f"ì£„ì†¡í•©ë‹ˆë‹¤. ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "confidence": 0.0,
                "sources": [],
                "response_time": time.time() - start_time
            }
    
    def _format_search_results(self, search_results: List[Document]) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ë¡œ ë³€í™˜"""
        context_parts = []
        for i, doc in enumerate(search_results, 1):
            context_parts.append(f"[ì°¸ê³ ìë£Œ {i}]\n{doc.page_content}")
        
        return "\n\n".join(context_parts)
    
    def _generate_response(self, query: str, context: str) -> str:
        """LLMì„ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„±"""
        prompt_template = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ì‡¼í•‘ëª° ê³ ê°ì„¼í„° ì§ì›ì…ë‹ˆë‹¤.
ì•„ë˜ ì°¸ê³ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³ ê°ì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ì°¸ê³ ìë£Œ:
{context}

ê³ ê° ì§ˆë¬¸: {query}

ë‹µë³€ ê°€ì´ë“œë¼ì¸:
1. ì°¸ê³ ìë£Œì— ìˆëŠ” ì •ë³´ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”
2. ì •í™•í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” ì œê³µí•˜ì§€ ë§ˆì„¸ìš”
3. ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” í†¤ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
4. í•„ìš”ì‹œ ì¶”ê°€ ë¬¸ì˜ë¥¼ ì•ˆë‚´í•˜ì„¸ìš”

ë‹µë³€:
""")
        
        try:
            messages = prompt_template.format_messages(
                context=context,
                query=query
            )
            
            response = self.llm.invoke(messages)
            return response.content.strip()
            
        except Exception as e:
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _extract_source_info(self, search_results: List[Document]) -> List[Dict[str, Any]]:
        """ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì†ŒìŠ¤ ì •ë³´ ì¶”ì¶œ"""
        sources = []
        for doc in search_results:
            source_info = {
                "source": doc.metadata.get("source", "unknown"),
                "content_preview": doc.page_content[:100] + "..." if len(doc.page_content) > 100 else doc.page_content,
                "metadata": doc.metadata
            }
            sources.append(source_info)
        
        return sources
    
    def _calculate_confidence(self, search_results: List[Document], query: str) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚° (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)"""
        if not search_results:
            return 0.0
        
        # ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ì— ë”°ë¥¸ ê¸°ë³¸ ì‹ ë¢°ë„
        base_confidence = min(len(search_results) * 0.3, 0.9)
        
        # ì¿¼ë¦¬ í‚¤ì›Œë“œê°€ ê²°ê³¼ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        query_lower = query.lower()
        keyword_matches = 0
        
        for doc in search_results:
            content_lower = doc.page_content.lower()
            if any(word in content_lower for word in query_lower.split() if len(word) > 2):
                keyword_matches += 1
        
        # í‚¤ì›Œë“œ ë§¤ì¹˜ì— ë”°ë¥¸ ì‹ ë¢°ë„ ì¡°ì •
        keyword_confidence = keyword_matches / len(search_results) * 0.3
        
        return min(base_confidence + keyword_confidence, 1.0)


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # RAG í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    rag = RAGProcessor()
    rag.initialize_vector_store()
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        "ë°°ì†¡ë¹„ëŠ” ì–¼ë§ˆì¸ê°€ìš”?",
        "ë¬´ì„  ì´ì–´í° ë°°í„°ë¦¬ ì§€ì†ì‹œê°„ì€?",
        "ë°˜í’ˆ ì ˆì°¨ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”"
    ]
    
    print("ğŸ” RAG í”„ë¡œì„¸ì„œ í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
    
    for query in test_queries:
        print(f"ì§ˆë¬¸: {query}")
        result = rag.process_query(query)
        
        print(f"ë‹µë³€: {result['response'][:200]}...")
        print(f"ì‹ ë¢°ë„: {result['confidence']:.2f}")
        print(f"ì‘ë‹µ ì‹œê°„: {result['response_time']:.2f}ì´ˆ")
        print(f"ì†ŒìŠ¤ ìˆ˜: {len(result['sources'])}")
        print("-" * 50)
