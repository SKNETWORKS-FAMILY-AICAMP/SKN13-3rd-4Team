"""
RAG (Retrieval-Augmented Generation) ì²˜ë¦¬ê¸°
FAQì™€ ìƒí’ˆ ì •ë³´ì— ëŒ€í•œ ë²¡í„° ê²€ìƒ‰ ë° ì‘ë‹µ ìƒì„±
"""
import json
from typing import List, Dict, Any
from pathlib import Path

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain.text_splitter import RecursiveCharacterTextSplitter

from dotenv import load_dotenv
load_dotenv()

class RAGProcessor:
    """RAG ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ ë° ì‘ë‹µ ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.data_dir = self.project_root / "data"
        self.vector_db_path = self.data_dir / "vectordb_chroma"
        
        # OpenAI ëª¨ë¸ ì´ˆê¸°í™”
        self.llm = ChatOpenAI(
            model="gpt-4",
            temperature=0.1
        )
        
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        self.embedding_model = OpenAIEmbeddings(
            model="text-embedding-3-large"
        )
        
        # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
        self.vector_store = None
        self.retriever = None
        
        # í…ìŠ¤íŠ¸ ë¶„í• ê¸°
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""]
        )
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        self.rag_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ì‡¼í•‘ëª° ê³ ê° ì„œë¹„ìŠ¤ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
            
ì£¼ìš” ì—­í• :
- ê³ ê°ì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ì¹œì ˆí•œ ë‹µë³€ ì œê³µ
- ì œê³µëœ ë¬¸ì„œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ìƒì„±
- ì •ë³´ê°€ ë¶€ì¡±í•œ ê²½ìš° ì •ì¤‘í•˜ê²Œ ì•ˆë‚´

ë‹µë³€ ê°€ì´ë“œë¼ì¸:
1. ì¹œê·¼í•˜ê³  ì •ì¤‘í•œ ì–´ì¡° ì‚¬ìš©
2. êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ ì œê³µ
3. ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ëŠ” ì¶”ì¸¡í•˜ì§€ ë§ê³  ì•ˆë‚´
4. í•„ìš”ì‹œ ì¶”ê°€ ë¬¸ì˜ ë°©ë²• ì•ˆë‚´

ê²€ìƒ‰ëœ ë¬¸ì„œ ì •ë³´:
{context}
"""),
            ("human", "{question}")
        ])
    
    def initialize_vector_store(self):
        """ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”"""
        try:
            # ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì‹œë„
            self.vector_store = Chroma(
                persist_directory=str(self.vector_db_path),
                embedding_function=self.embedding_model,
                collection_name="ecommerce_docs"
            )
            
            # ë¬¸ì„œê°€ ìˆëŠ”ì§€ í™•ì¸
            if self.vector_store._collection.count() == 0:
                print("ğŸ“„ ë²¡í„° ìŠ¤í† ì–´ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë¬¸ì„œë¥¼ ì„ë² ë”©í•©ë‹ˆë‹¤...")
                self._embed_documents()
            else:
                print(f"âœ… ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ (ë¬¸ì„œ ìˆ˜: {self.vector_store._collection.count()})")
            
            # ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì •
            self.retriever = self.vector_store.as_retriever(
                search_type="similarity",
                search_kwargs={"k": 3}
            )
            
        except Exception as e:
            print(f"âŒ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print("ğŸ“„ ìƒˆë¡œìš´ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
            self._create_new_vector_store()
    
    def _create_new_vector_store(self):
        """ìƒˆë¡œìš´ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±"""
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.vector_db_path.mkdir(parents=True, exist_ok=True)
        
        # ìƒˆ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
        self.vector_store = Chroma(
            persist_directory=str(self.vector_db_path),
            embedding_function=self.embedding_model,
            collection_name="ecommerce_docs"
        )
        
        # ë¬¸ì„œ ì„ë² ë”©
        self._embed_documents()
        
        # ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì •
        self.retriever = self.vector_store.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 3}
        )
    
    def _embed_documents(self):
        """ë¬¸ì„œë“¤ì„ ì„ë² ë”©í•˜ì—¬ ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥"""
        documents = []
        
        # FAQ ë¬¸ì„œ ì²˜ë¦¬
        faq_docs = self._process_faq_documents()
        documents.extend(faq_docs)
        
        # ìƒí’ˆ ì •ë³´ ë¬¸ì„œ ì²˜ë¦¬
        product_docs = self._process_product_documents()
        documents.extend(product_docs)
        
        if documents:
            # ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• 
            split_docs = self.text_splitter.split_documents(documents)
            
            # ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€
            self.vector_store.add_documents(split_docs)
            print(f"âœ… {len(split_docs)}ê°œ ë¬¸ì„œ ì²­í¬ê°€ ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print("âš ï¸ ì„ë² ë”©í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    def _process_faq_documents(self) -> List[Document]:
        """FAQ ë°ì´í„°ë¥¼ Document ê°ì²´ë¡œ ë³€í™˜"""
        documents = []
        faq_file = self.data_dir / "raw_docs" / "faq_data.json"
        
        if faq_file.exists():
            with open(faq_file, 'r', encoding='utf-8') as f:
                faq_data = json.load(f)
            
            for faq in faq_data:
                content = f"ì§ˆë¬¸: {faq['question']}\në‹µë³€: {faq['answer']}"
                doc = Document(
                    page_content=content,
                    metadata={
                        "source": "faq",
                        "category": faq['category'],
                        "faq_id": faq['id'],
                        "keywords": faq['keywords']
                    }
                )
                documents.append(doc)
            
            print(f"ğŸ“‹ FAQ ë¬¸ì„œ {len(documents)}ê°œ ì²˜ë¦¬ ì™„ë£Œ")
        
        return documents
    
    def _process_product_documents(self) -> List[Document]:
        """ìƒí’ˆ ì •ë³´ë¥¼ Document ê°ì²´ë¡œ ë³€í™˜"""
        documents = []
        product_file = self.data_dir / "raw_docs" / "product_info.json"
        
        if product_file.exists():
            with open(product_file, 'r', encoding='utf-8') as f:
                product_data = json.load(f)
            
            for product in product_data:
                # ìƒí’ˆ ê¸°ë³¸ ì •ë³´
                content = f"ìƒí’ˆëª…: {product['name']}\n"
                content += f"ì¹´í…Œê³ ë¦¬: {product['category']}\n"
                content += f"ì„¤ëª…: {product['description']}\n"
                content += f"ê°€ê²©: {product['price']:,}ì›\n"
                
                # ì‚¬ì–‘ ì •ë³´
                if 'specifications' in product:
                    content += "\nì‚¬ì–‘:\n"
                    for key, value in product['specifications'].items():
                        content += f"- {key}: {value}\n"
                
                # íŠ¹ì§• ì •ë³´
                if 'features' in product:
                    content += "\nì£¼ìš” íŠ¹ì§•:\n"
                    for feature in product['features']:
                        content += f"- {feature}\n"
                
                doc = Document(
                    page_content=content,
                    metadata={
                        "source": "product",
                        "product_id": product['product_id'],
                        "category": product['category'],
                        "price": product['price'],
                        "keywords": product['keywords']
                    }
                )
                documents.append(doc)
            
            print(f"ğŸ›ï¸ ìƒí’ˆ ë¬¸ì„œ {len(documents)}ê°œ ì²˜ë¦¬ ì™„ë£Œ")
        
        return documents
    
    def search_documents(self, query: str, k: int = 3) -> List[Document]:
        """ë¬¸ì„œ ê²€ìƒ‰"""
        if not self.retriever:
            self.initialize_vector_store()
        
        try:
            results = self.retriever.invoke(query)
            return results[:k]
        except Exception as e:
            print(f"âŒ ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def generate_response(self, query: str, context_docs: List[Document]) -> str:
        """ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ë‹µ ìƒì„±"""
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = "\n\n".join([doc.page_content for doc in context_docs])

        # ì²´ì¸ ì‹¤í–‰ (LangSmith ìë™ íŠ¸ë ˆì´ì‹±)
        chain = self.rag_prompt | self.llm

        try:
            # LangSmithì—ì„œ ì´ í˜¸ì¶œì„ ì¶”ì í•  ìˆ˜ ìˆë„ë¡ ë©”íƒ€ë°ì´í„° ì¶”ê°€
            response = chain.invoke(
                {
                    "context": context,
                    "question": query
                },
                config={
                    "metadata": {
                        "component": "RAGProcessor",
                        "operation": "generate_response",
                        "context_docs_count": len(context_docs),
                        "query_length": len(query)
                    }
                }
            )
            return response.content
        except Exception as e:
            print(f"âŒ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì‹œìŠ¤í…œì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    def process_query(self, query: str) -> Dict[str, Any]:
        """ì¿¼ë¦¬ ì²˜ë¦¬ (ê²€ìƒ‰ + ì‘ë‹µ ìƒì„±)"""
        # ë¬¸ì„œ ê²€ìƒ‰
        relevant_docs = self.search_documents(query)
        
        if not relevant_docs:
            return {
                "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê³ ê°ì„¼í„°(1588-1234)ë¡œ ë¬¸ì˜í•´ì£¼ì‹œë©´ ë” ìì„¸í•œ ë„ì›€ì„ ë°›ìœ¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "sources": [],
                "confidence": 0.0
            }
        
        # ì‘ë‹µ ìƒì„±
        response = self.generate_response(query, relevant_docs)
        
        # ì†ŒìŠ¤ ì •ë³´ ì¶”ì¶œ
        sources = []
        for doc in relevant_docs:
            source_info = {
                "source": doc.metadata.get("source", "unknown"),
                "content_preview": doc.page_content[:100] + "..." if len(doc.page_content) > 100 else doc.page_content
            }
            if doc.metadata.get("source") == "product":
                source_info["product_id"] = doc.metadata.get("product_id")
            elif doc.metadata.get("source") == "faq":
                source_info["faq_id"] = doc.metadata.get("faq_id")
                source_info["category"] = doc.metadata.get("category")
            
            sources.append(source_info)
        
        return {
            "response": response,
            "sources": sources,
            "confidence": len(relevant_docs) / 3.0  # ê°„ë‹¨í•œ ì‹ ë¢°ë„ ê³„ì‚°
        }

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    rag = RAGProcessor()
    rag.initialize_vector_store()
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    test_queries = [
        "ë°°ì†¡ë¹„ëŠ” ì–¼ë§ˆì¸ê°€ìš”?",
        "ë¬´ì„  ì´ì–´í° ì‚¬ì–‘ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
        "ë°˜í’ˆì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?"
    ]
    
    for query in test_queries:
        print(f"\nğŸ” ì§ˆë¬¸: {query}")
        result = rag.process_query(query)
        print(f"ğŸ’¬ ë‹µë³€: {result['response']}")
        print(f"ğŸ“Š ì‹ ë¢°ë„: {result['confidence']:.2f}")
        print(f"ğŸ“š ì†ŒìŠ¤ ìˆ˜: {len(result['sources'])}")
